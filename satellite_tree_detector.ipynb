{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tree Detection Pipeline - Dependency Installer for Google Colab\n",
    "\n",
    "Run this ONCE at the start of your Colab session.\n",
    "After installation, you can reload/modify the main script without reinstalling.\n",
    "\n",
    "Usage:\n",
    "%run colab_install_deps.py\n",
    "\"\"\"\n",
    "\n",
    "print(\"Installing dependencies for Tree Detection Pipeline...\")\n",
    "print(\"This will take ~5-10 minutes (ONE TIME only)\")\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install only YOLO + SegFormer requirements\"\"\"\n",
    "    packages = [\n",
    "        \"torch torchvision\",\n",
    "        \"transformers>=4.35.0\",\n",
    "        \"huggingface_hub\",\n",
    "        \"ultralytics>=8.3.184\",\n",
    "        \"opencv-python>=4.8.0\",\n",
    "        \"tqdm>=4.65.0\",\n",
    "        \"PyYAML>=6.0\",\n",
    "        \"Pillow>=10.0.0\",\n",
    "        \"rasterio\",\n",
    "        \"shapely>=2.0.0\",\n",
    "        \"pyproj>=3.4.0\",\n",
    "        \"requests>=2.25.0\",\n",
    "        \"mercantile>=1.2.0\",\n",
    "        \"safetensors\",\n",
    "    ]\n",
    "\n",
    "    for i, package in enumerate(packages, 1):\n",
    "        print(f\"\\n[{i}/{len(packages)}] Installing {package.split()[0]}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + package.split())\n",
    "\n",
    "# Install system dependencies\n",
    "print(\"\\nInstalling system dependencies...\")\n",
    "subprocess.run([\"apt-get\", \"update\", \"-qq\"], check=True)\n",
    "subprocess.run([\"apt-get\", \"install\", \"-y\", \"-qq\", \"libgdal-dev\", \"gdal-bin\"], check=True)\n",
    "\n",
    "# Install Python packages\n",
    "print(\"\\nInstalling Python packages...\")\n",
    "install_packages()\n",
    "\n",
    "print(\"\\nAll dependencies installed successfully!\")\n",
    "print(\"Now run the main script: %run tree_detection_colab_main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_type": "markdown"
   },
   "source": [
    "Tree Detection Pipeline - YOLO Only (Multi-City Parallel Version)\n",
    "\n",
    "This is a LIGHTWEIGHT script for tree detection using YOLO with:\n",
    "- Multi-city support (array of bounding boxes)\n",
    "- Parallel download and inference\n",
    "- Resume capability per city\n",
    "\n",
    "Run this AFTER installing dependencies with colab_install_deps.py.\n",
    "\n",
    "Usage:\n",
    "1. First run: Execute colab_install_deps.py (5-10 minutes, once per session)\n",
    "2. Then run this script (fast, can reload for parameter changes)\n",
    "3. Edit CONFIGURATION section below as needed\n",
    "4. Re-run anytime to test new parameters\n",
    "\n",
    "This notebook uses MapTiler APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: IMPORT ALL REQUIRED LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import glob\n",
    "import gc\n",
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "from typing import Dict, Tuple, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import mercantile\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_city_logger(city_name: str, output_folder: str):\n",
    "    \"\"\"Setup a separate logger for each city\"\"\"\n",
    "    city_logger = logging.getLogger(f\"city_{city_name}\")\n",
    "    city_logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Remove existing handlers\n",
    "    city_logger.handlers = []\n",
    "\n",
    "    # File handler\n",
    "    if LOG_TO_FILE:\n",
    "        log_file = os.path.join(output_folder, f\"{city_name}_processing.log\")\n",
    "        file_handler = logging.FileHandler(log_file, mode='a')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        city_logger.addHandler(file_handler)\n",
    "\n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
    "    city_logger.addHandler(console_handler)\n",
    "\n",
    "    return city_logger\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - EDIT THESE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# ==== AREAS OF INTEREST (Multi-City Support) ====\n",
    "# Each entry: {\"name\": \"city_name\", \"bbox\": (west, south, east, north)}\n",
    "# Use http://bboxfinder.com to get coordinates\n",
    "\n",
    "CITIES = [\n",
    "    {\"name\": \"YourCity\", \"bbox\": (0.0, 0.0, 0.0, 0.0)},\n",
    "]\n",
    "\n",
    "# ==== YOLO MODEL SETTINGS ====\n",
    "YOLO_MODEL_PATH = \"/content/drive/MyDrive/your_model.pt\"\n",
    "YOLO_CONFIDENCE = 0.5\n",
    "\n",
    "# ==== MAPTILER API ====\n",
    "MAPTILER_API_KEY = \"YOUR_API_KEY_HERE\"  # Get free key at https://www.maptiler.com/cloud/\n",
    "\n",
    "# ==== PROCESSING SETTINGS ====\n",
    "ZOOM_LEVEL = 18            # Zoom level (10-18). None for auto-calculation\n",
    "MAX_TILES = None           # Maximum tiles to process PER CITY. None = process ALL tiles\n",
    "TILE_SIZE = 512            # Tile size in pixels\n",
    "DOWNLOAD_THREADS = 8       # Number of parallel download threads\n",
    "INFERENCE_BATCH_SIZE = 16  # Number of tiles to process together in YOLO (GPU optimization)\n",
    "SAVE_IMAGES = False        # Save annotated images (takes more space)\n",
    "LOG_TO_FILE = True         # Save detailed logs to file\n",
    "\n",
    "# ==== OUTPUT FOLDER ====\n",
    "OUTPUT_BASE_FOLDER = \"/content/drive/MyDrive/detections\"\n",
    "\n",
    "# ============================================================================\n",
    "# END CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nYOLO Model: {YOLO_MODEL_PATH}\")\n",
    "print(f\"YOLO Confidence: {YOLO_CONFIDENCE}\")\n",
    "print(f\"Cities to process: {len(CITIES)}\")\n",
    "for city in CITIES:\n",
    "    print(f\"  - {city['name']}: {city['bbox']}\")\n",
    "print(f\"Download threads: {DOWNLOAD_THREADS}\")\n",
    "print(f\"Max Tiles per city: {MAX_TILES}\")\n",
    "print(f\"Output base: {OUTPUT_BASE_FOLDER}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: DATA STRUCTURES\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class TileRequest:\n",
    "    \"\"\"Represents a tile download request\"\"\"\n",
    "    city_name: str\n",
    "    x: int\n",
    "    y: int\n",
    "    zoom: int\n",
    "    tile_size: int\n",
    "\n",
    "@dataclass\n",
    "class TileResult:\n",
    "    \"\"\"Represents a downloaded tile ready for processing\"\"\"\n",
    "    city_name: str\n",
    "    data: Dict\n",
    "    x: int\n",
    "    y: int\n",
    "    zoom: int\n",
    "    bbox: Tuple\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Detect and return the best available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"Using CPU (will be slower)\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: MAPTILER API CLIENT\n",
    "# ============================================================================\n",
    "\n",
    "class MapTilerAPI:\n",
    "    \"\"\"MapTiler API integration with thread-safety\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, max_retries: int = 3):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.maptiler.com/maps\"\n",
    "        self.max_retries = max_retries\n",
    "        # Thread-local session\n",
    "        self.thread_local = threading.local()\n",
    "\n",
    "    def _get_session(self):\n",
    "        \"\"\"Get thread-local session\"\"\"\n",
    "        if not hasattr(self.thread_local, \"session\"):\n",
    "            self.thread_local.session = requests.Session()\n",
    "        return self.thread_local.session\n",
    "\n",
    "    def fetch_single_tile(self, x: int, y: int, zoom: int, tile_size: int = 512, format: str = \"jpg\"):\n",
    "        \"\"\"Fetch a single tile and return as georeferenced data with retry logic\"\"\"\n",
    "        url = f\"{self.base_url}/satellite/{zoom}/{x}/{y}.{format}\"\n",
    "        params = {\"key\": self.api_key}\n",
    "        session = self._get_session()\n",
    "\n",
    "        # Retry logic with exponential backoff\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = session.get(url, params=params, timeout=30)\n",
    "\n",
    "                # If status is 500, retry with exponential backoff\n",
    "                if response.status_code == 500:\n",
    "                    wait_time = (2 ** attempt)  # 1s, 2s, 4s\n",
    "                    logger.warning(f\"MapTiler returned 500 for tile {x}/{y}/{zoom}. Attempt {attempt + 1}/{self.max_retries}. Retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Convert to georeferenced array\n",
    "                image = Image.open(io.BytesIO(response.content))\n",
    "                if image.mode != 'RGB':\n",
    "                    image = image.convert('RGB')\n",
    "                img_array = np.array(image)\n",
    "\n",
    "                # Get bounds\n",
    "                n = 2.0 ** zoom\n",
    "                west = x / n * 360.0 - 180.0\n",
    "                east = (x + 1) / n * 360.0 - 180.0\n",
    "                import math\n",
    "                lat_rad_top = math.atan(math.sinh(math.pi * (1 - 2 * y / n)))\n",
    "                lat_rad_bottom = math.atan(math.sinh(math.pi * (1 - 2 * (y + 1) / n)))\n",
    "                north = math.degrees(lat_rad_top)\n",
    "                south = math.degrees(lat_rad_bottom)\n",
    "\n",
    "                return {\n",
    "                    \"array\": img_array,\n",
    "                    \"bounds\": (west, south, east, north),\n",
    "                    \"width\": image.width,\n",
    "                    \"height\": image.height\n",
    "                }\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    wait_time = (2 ** attempt)\n",
    "                    logger.warning(f\"Request error for tile {x}/{y}/{zoom}: {e}. Retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    logger.error(f\"Failed to fetch tile {x}/{y}/{zoom} after {self.max_retries} attempts: {e}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unexpected error fetching tile {x}/{y}/{zoom}: {e}\")\n",
    "                return None\n",
    "\n",
    "        # If all retries failed\n",
    "        logger.error(f\"Failed to fetch tile {x}/{y}/{zoom} after {self.max_retries} attempts\")\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: PARALLEL DOWNLOAD WORKER\n",
    "# ============================================================================\n",
    "\n",
    "class TileDownloader:\n",
    "    \"\"\"Manages parallel tile downloads\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, num_threads: int = 4):\n",
    "        self.maptiler = MapTilerAPI(api_key)\n",
    "        self.num_threads = num_threads\n",
    "        self.download_queue = Queue()\n",
    "        self.result_queue = Queue()\n",
    "        self.threads = []\n",
    "        self.stop_event = threading.Event()\n",
    "\n",
    "    def _download_worker(self):\n",
    "        \"\"\"Worker thread for downloading tiles\"\"\"\n",
    "        while not self.stop_event.is_set():\n",
    "            try:\n",
    "                # Get tile request with timeout to allow checking stop_event\n",
    "                tile_request = self.download_queue.get(timeout=1)\n",
    "\n",
    "                if tile_request is None:  # Poison pill\n",
    "                    break\n",
    "\n",
    "                # Download tile\n",
    "                tile_data = self.maptiler.fetch_single_tile(\n",
    "                    tile_request.x,\n",
    "                    tile_request.y,\n",
    "                    tile_request.zoom,\n",
    "                    tile_request.tile_size\n",
    "                )\n",
    "\n",
    "                if tile_data:\n",
    "                    # Get bbox for this tile\n",
    "                    n = 2.0 ** tile_request.zoom\n",
    "                    west = tile_request.x / n * 360.0 - 180.0\n",
    "                    east = (tile_request.x + 1) / n * 360.0 - 180.0\n",
    "                    import math\n",
    "                    lat_rad_top = math.atan(math.sinh(math.pi * (1 - 2 * tile_request.y / n)))\n",
    "                    lat_rad_bottom = math.atan(math.sinh(math.pi * (1 - 2 * (tile_request.y + 1) / n)))\n",
    "                    north = math.degrees(lat_rad_top)\n",
    "                    south = math.degrees(lat_rad_bottom)\n",
    "\n",
    "                    tile_result = TileResult(\n",
    "                        city_name=tile_request.city_name,\n",
    "                        data=tile_data,\n",
    "                        x=tile_request.x,\n",
    "                        y=tile_request.y,\n",
    "                        zoom=tile_request.zoom,\n",
    "                        bbox=(north, south, east, west)\n",
    "                    )\n",
    "                    self.result_queue.put(tile_result)\n",
    "                else:\n",
    "                    # Put None to indicate failed download\n",
    "                    self.result_queue.put(None)\n",
    "\n",
    "                self.download_queue.task_done()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start download threads\"\"\"\n",
    "        self.stop_event.clear()\n",
    "        for _ in range(self.num_threads):\n",
    "            thread = threading.Thread(target=self._download_worker, daemon=True)\n",
    "            thread.start()\n",
    "            self.threads.append(thread)\n",
    "\n",
    "    def add_tile(self, tile_request: TileRequest):\n",
    "        \"\"\"Add a tile to download queue\"\"\"\n",
    "        self.download_queue.put(tile_request)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop all download threads\"\"\"\n",
    "        # Send poison pills\n",
    "        for _ in range(self.num_threads):\n",
    "            self.download_queue.put(None)\n",
    "\n",
    "        # Wait for threads to finish\n",
    "        for thread in self.threads:\n",
    "            thread.join()\n",
    "\n",
    "        self.threads = []\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: YOLO INFERENCE FUNCTION (WITH BATCH SUPPORT)\n",
    "# ============================================================================\n",
    "\n",
    "def run_yolo_inference_single(image_array: np.ndarray, model, conf: float, device: str):\n",
    "    \"\"\"Run YOLO inference on a single image\"\"\"\n",
    "    results_raw = model(image_array, conf=conf, device=device, verbose=False)\n",
    "\n",
    "    detections = []\n",
    "    for result in results_raw:\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            confidences = result.boxes.conf.cpu().numpy()\n",
    "            \n",
    "            for i, (box, confidence) in enumerate(zip(boxes, confidences)):\n",
    "                x1, y1, x2, y2 = box.astype(int)\n",
    "                detections.append({\n",
    "                    \"id\": i,\n",
    "                    \"confidence\": float(confidence),\n",
    "                    \"bbox\": {\"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2)}\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"trees_detected\": len(detections),\n",
    "        \"detections\": detections,\n",
    "        \"image_size\": {\"width\": image_array.shape[1], \"height\": image_array.shape[0]}\n",
    "    }\n",
    "\n",
    "def run_yolo_inference_batch(image_arrays: List[np.ndarray], model, conf: float, device: str):\n",
    "    \"\"\"Run YOLO inference on a batch of images for better GPU utilization\"\"\"\n",
    "    if len(image_arrays) == 0:\n",
    "        return []\n",
    "\n",
    "    # Run batch inference\n",
    "    results_raw = model(image_arrays, conf=conf, device=device, verbose=False)\n",
    "\n",
    "    batch_results = []\n",
    "    for result in results_raw:\n",
    "        detections = []\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            confidences = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "            for i, (box, confidence) in enumerate(zip(boxes, confidences)):\n",
    "                x1, y1, x2, y2 = box.astype(int)\n",
    "                detections.append({\n",
    "                    \"id\": i,\n",
    "                    \"confidence\": float(confidence),\n",
    "                    \"bbox\": {\"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2)}\n",
    "                })\n",
    "\n",
    "        batch_results.append({\n",
    "            \"trees_detected\": len(detections),\n",
    "            \"detections\": detections,\n",
    "            \"image_size\": {\"width\": result.orig_shape[1], \"height\": result.orig_shape[0]}\n",
    "        })\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "# ============================================================================\n",
    "# PART 8: PROCESSING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def process_tile(tile_result: TileResult, model, yolo_conf: float, device: str):\n",
    "    \"\"\"Process a single tile with YOLO detection using pre-loaded model\"\"\"\n",
    "    try:\n",
    "        image_array = tile_result.data[\"array\"]\n",
    "        bounds = tile_result.data[\"bounds\"]\n",
    "        tile_id = f\"tile_{tile_result.zoom}_{tile_result.x}_{tile_result.y}\"\n",
    "\n",
    "        # Run YOLO inference with pre-loaded model\n",
    "        yolo_results = run_yolo_inference_single(image_array, model, yolo_conf, device)\n",
    "\n",
    "        # Create result\n",
    "        results = {\n",
    "            \"image_id\": tile_id,\n",
    "            \"image_bounds\": bounds,\n",
    "            \"image_size\": yolo_results[\"image_size\"],\n",
    "            \"tile_x\": tile_result.x,\n",
    "            \"tile_y\": tile_result.y,\n",
    "            \"tile_zoom\": tile_result.zoom,\n",
    "            \"tile_bbox\": tile_result.bbox,\n",
    "            \"trees_detected\": yolo_results[\"trees_detected\"],\n",
    "            \"detections\": yolo_results[\"detections\"],\n",
    "            \"confidence\": yolo_conf,\n",
    "            \"city\": tile_result.city_name\n",
    "        }\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing tile: {e}\")\n",
    "        return {\"error\": str(e), \"city\": tile_result.city_name}\n",
    "\n",
    "def process_tile_batch(tile_results: List[TileResult], model, yolo_conf: float, device: str):\n",
    "    \"\"\"Process a batch of tiles with YOLO for better GPU utilization\"\"\"\n",
    "    if len(tile_results) == 0:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # Prepare batch of images\n",
    "        image_arrays = [tr.data[\"array\"] for tr in tile_results]\n",
    "\n",
    "        # Run batch inference\n",
    "        batch_yolo_results = run_yolo_inference_batch(image_arrays, model, yolo_conf, device)\n",
    "\n",
    "        # Create results for each tile\n",
    "        results = []\n",
    "        for tile_result, yolo_result in zip(tile_results, batch_yolo_results):\n",
    "            bounds = tile_result.data[\"bounds\"]\n",
    "            tile_id = f\"tile_{tile_result.zoom}_{tile_result.x}_{tile_result.y}\"\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": tile_id,\n",
    "                \"image_bounds\": bounds,\n",
    "                \"image_size\": yolo_result[\"image_size\"],\n",
    "                \"tile_x\": tile_result.x,\n",
    "                \"tile_y\": tile_result.y,\n",
    "                \"tile_zoom\": tile_result.zoom,\n",
    "                \"tile_bbox\": tile_result.bbox,\n",
    "                \"trees_detected\": yolo_result[\"trees_detected\"],\n",
    "                \"detections\": yolo_result[\"detections\"],\n",
    "                \"confidence\": yolo_conf,\n",
    "                \"city\": tile_result.city_name\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing batch: {e}\")\n",
    "        # Fall back to single processing\n",
    "        return [process_tile(tr, model, yolo_conf, device) for tr in tile_results]\n",
    "\n",
    "def get_last_processed_tile(output_folder):\n",
    "    \"\"\"Find the last successfully processed tile to enable resume\"\"\"\n",
    "    json_folder = os.path.join(output_folder, \"json\")\n",
    "    if not os.path.exists(json_folder):\n",
    "        return None\n",
    "\n",
    "    # Find all result files\n",
    "    result_files = glob.glob(os.path.join(json_folder, \"tile_*_results.json\"))\n",
    "    if not result_files:\n",
    "        return None\n",
    "\n",
    "    # Parse tile coordinates from filenames\n",
    "    tiles_processed = []\n",
    "    for filepath in result_files:\n",
    "        try:\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Format: tile_zoom_x_y_results.json\n",
    "            parts = filename.replace(\"_results.json\", \"\").split(\"_\")\n",
    "            if len(parts) >= 4 and parts[0] == \"tile\":\n",
    "                zoom = int(parts[1])\n",
    "                x = int(parts[2])\n",
    "                y = int(parts[3])\n",
    "                tiles_processed.append((zoom, x, y))\n",
    "        except (ValueError, IndexError) as e:\n",
    "            logger.warning(f\"Could not parse tile from filename {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not tiles_processed:\n",
    "        return None\n",
    "\n",
    "    logger.info(f\"Found {len(tiles_processed)} previously processed tiles\")\n",
    "    return set(tiles_processed)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 9: MAIN PIPELINE (PARALLEL VERSION)\n",
    "# ============================================================================\n",
    "\n",
    "def run_pipeline_parallel(city_config: Dict, yolo_model, yolo_conf: float,\n",
    "                         downloader: TileDownloader, device: str,\n",
    "                         max_tiles: int, zoom: int):\n",
    "    \"\"\"Run the complete detection pipeline for a single city with parallel processing and batch inference\"\"\"\n",
    "\n",
    "    city_name = city_config[\"name\"]\n",
    "    bbox = city_config[\"bbox\"]\n",
    "\n",
    "    # Setup output folder for this city\n",
    "    output_folder = os.path.join(OUTPUT_BASE_FOLDER, f\"{city_name}_zoom{zoom}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, \"json\"), exist_ok=True)\n",
    "\n",
    "    # Setup city-specific logger\n",
    "    city_logger = setup_city_logger(city_name, output_folder)\n",
    "\n",
    "    city_logger.info(f\"{'='*70}\")\n",
    "    city_logger.info(f\"PROCESSING CITY: {city_name.upper()}\")\n",
    "    city_logger.info(f\"{'='*70}\")\n",
    "    city_logger.info(f\"Bounding box: {bbox}\")\n",
    "    city_logger.info(f\"Zoom level: {zoom}\")\n",
    "    city_logger.info(f\"Output folder: {output_folder}\")\n",
    "\n",
    "    # Check for previously processed tiles\n",
    "    processed_tiles = get_last_processed_tile(output_folder)\n",
    "    resume_mode = processed_tiles is not None and len(processed_tiles) > 0\n",
    "\n",
    "    # Get tile coordinates at specified zoom\n",
    "    tiles_coords = list(mercantile.tiles(*bbox, zooms=zoom))\n",
    "    total_tiles = len(tiles_coords)\n",
    "\n",
    "    city_logger.info(f\"Total tiles at zoom {zoom}: {total_tiles}\")\n",
    "\n",
    "    # Filter out already processed tiles if resuming\n",
    "    if resume_mode:\n",
    "        original_count = len(tiles_coords)\n",
    "        tiles_coords = [t for t in tiles_coords if (t.z, t.x, t.y) not in processed_tiles]\n",
    "        skipped_count = original_count - len(tiles_coords)\n",
    "        city_logger.info(f\"RESUME MODE: Found {len(processed_tiles)} previously processed tiles\")\n",
    "        city_logger.info(f\"Skipping {skipped_count} already completed tiles\")\n",
    "        city_logger.info(f\"Remaining to process: {len(tiles_coords)} tiles\")\n",
    "\n",
    "    if max_tiles is not None and len(tiles_coords) > max_tiles:\n",
    "        tiles_coords = tiles_coords[:max_tiles]\n",
    "        city_logger.info(f\"Limiting to {max_tiles} tiles (out of {total_tiles} total)\")\n",
    "    elif not resume_mode:\n",
    "        city_logger.info(f\"Processing ALL {len(tiles_coords)} tiles (no limit)\")\n",
    "\n",
    "    if len(tiles_coords) == 0:\n",
    "        city_logger.info(f\"All tiles already processed for {city_name}! Nothing to do.\")\n",
    "        # Load existing results for stats\n",
    "        return load_existing_results(output_folder), zoom\n",
    "\n",
    "    city_logger.info(f\"Starting parallel processing of {len(tiles_coords)} tiles...\")\n",
    "    city_logger.info(f\"Download threads: {DOWNLOAD_THREADS}\")\n",
    "    city_logger.info(f\"Inference batch size: {INFERENCE_BATCH_SIZE}\")\n",
    "    city_logger.info(f\"Processing with YOLO on {device}\")\n",
    "\n",
    "    # Queue all tiles for download\n",
    "    for tile in tiles_coords:\n",
    "        tile_request = TileRequest(\n",
    "            city_name=city_name,\n",
    "            x=tile.x,\n",
    "            y=tile.y,\n",
    "            zoom=tile.z,\n",
    "            tile_size=TILE_SIZE\n",
    "        )\n",
    "        downloader.add_tile(tile_request)\n",
    "\n",
    "    # Process tiles in batches as they come in\n",
    "    all_results = []\n",
    "    json_folder = os.path.join(output_folder, \"json\")\n",
    "    tiles_to_process = len(tiles_coords)\n",
    "    processed_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    # Batch collection\n",
    "    tile_batch = []\n",
    "    start_time = time.time()\n",
    "    last_progress_time = start_time\n",
    "\n",
    "    while processed_count + failed_count < tiles_to_process:\n",
    "        try:\n",
    "            # Collect tiles for batch (with timeout to prevent infinite wait)\n",
    "            timeout = 2.0 if len(tile_batch) > 0 else 60.0\n",
    "\n",
    "            try:\n",
    "                tile_result = downloader.result_queue.get(timeout=timeout)\n",
    "\n",
    "                if tile_result is None:\n",
    "                    # Failed download\n",
    "                    failed_count += 1\n",
    "                    city_logger.warning(f\"Download failed | Progress: {processed_count}/{tiles_to_process} | Failed: {failed_count}\")\n",
    "                    continue\n",
    "\n",
    "                tile_batch.append(tile_result)\n",
    "\n",
    "            except:\n",
    "                # Timeout - process what we have if batch is not empty\n",
    "                if len(tile_batch) == 0:\n",
    "                    continue\n",
    "\n",
    "            # Process batch when full or timeout occurred\n",
    "            if len(tile_batch) >= INFERENCE_BATCH_SIZE or (len(tile_batch) > 0 and processed_count + failed_count + len(tile_batch) >= tiles_to_process):\n",
    "                # Process batch with YOLO\n",
    "                batch_results = process_tile_batch(tile_batch, yolo_model, yolo_conf, device)\n",
    "\n",
    "                # Save results\n",
    "                for result in batch_results:\n",
    "                    all_results.append(result)\n",
    "\n",
    "                    # Save JSON immediately\n",
    "                    tile_id = result.get(\"image_id\", \"unknown\")\n",
    "                    json_path = os.path.join(json_folder, f\"{tile_id}_results.json\")\n",
    "                    with open(json_path, 'w') as f:\n",
    "                        json.dump(result, f, indent=2)\n",
    "\n",
    "                    processed_count += 1\n",
    "\n",
    "                # Progress update\n",
    "                current_time = time.time()\n",
    "                if current_time - last_progress_time >= 5.0:  # Update every 5 seconds\n",
    "                    elapsed = current_time - start_time\n",
    "                    rate = processed_count / elapsed if elapsed > 0 else 0\n",
    "                    remaining = tiles_to_process - processed_count - failed_count\n",
    "                    eta = remaining / rate if rate > 0 else 0\n",
    "\n",
    "                    total_trees = sum(r.get(\"trees_detected\", 0) for r in all_results)\n",
    "\n",
    "                    city_logger.info(\n",
    "                        f\"Progress: {processed_count}/{tiles_to_process} | \"\n",
    "                        f\"Trees: {total_trees} | \"\n",
    "                        f\"Rate: {rate:.1f} tiles/s | \"\n",
    "                        f\"ETA: {eta/60:.1f}m | \"\n",
    "                        f\"Failed: {failed_count}\"\n",
    "                    )\n",
    "                    last_progress_time = current_time\n",
    "\n",
    "                # Clear batch\n",
    "                tile_batch = []\n",
    "\n",
    "                # Periodic memory cleanup\n",
    "                if processed_count % 100 == 0:\n",
    "                    gc.collect()\n",
    "                    if device == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            city_logger.error(f\"Error in processing loop: {e}\")\n",
    "            failed_count += 1\n",
    "            tile_batch = []  # Clear batch on error\n",
    "            continue\n",
    "\n",
    "    elapsed_total = time.time() - start_time\n",
    "    city_logger.info(f\"{city_name} processing complete!\")\n",
    "    city_logger.info(f\"Processed: {processed_count} tiles in {elapsed_total/60:.1f} minutes\")\n",
    "    city_logger.info(f\"Average rate: {processed_count/elapsed_total:.2f} tiles/second\")\n",
    "    city_logger.info(f\"Failed: {failed_count}\")\n",
    "\n",
    "    return all_results, zoom\n",
    "\n",
    "def load_existing_results(output_folder):\n",
    "    \"\"\"Load existing results from JSON files\"\"\"\n",
    "    json_folder = os.path.join(output_folder, \"json\")\n",
    "    all_result_files = glob.glob(os.path.join(json_folder, \"tile_*_results.json\"))\n",
    "    results = []\n",
    "    for filepath in all_result_files:\n",
    "        with open(filepath, 'r') as f:\n",
    "            results.append(json.load(f))\n",
    "    return results\n",
    "\n",
    "# ============================================================================\n",
    "# PART 10: GEOJSON CREATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_geojson(results, output_folder, city_name):\n",
    "    \"\"\"Create GeoJSON from YOLO detection results\"\"\"\n",
    "    yolo_path = os.path.join(output_folder, f'{city_name}_yolo_detections.geojson')\n",
    "\n",
    "    def pixel_to_latlon(pixel_x, pixel_y, bounds, size):\n",
    "        west, south, east, north = bounds\n",
    "        width, height = size['width'], size['height']\n",
    "        lon = west + (pixel_x / width) * (east - west)\n",
    "        lat = north - (pixel_y / height) * (north - south)\n",
    "        return lat, lon\n",
    "\n",
    "    # Create YOLO GeoJSON\n",
    "    with open(yolo_path, 'w') as f:\n",
    "        f.write('{\\n')\n",
    "        f.write('  \"type\": \"FeatureCollection\",\\n')\n",
    "        f.write('  \"features\": [\\n')\n",
    "\n",
    "        first = True\n",
    "        for result in results:\n",
    "            if 'error' in result:\n",
    "                continue\n",
    "\n",
    "            bounds = result.get('image_bounds')\n",
    "            size = result.get('image_size')\n",
    "\n",
    "            if not bounds or not size:\n",
    "                continue\n",
    "\n",
    "            # Process YOLO detections\n",
    "            if 'detections' in result:\n",
    "                for det in result['detections']:\n",
    "                    bbox_coords = det['bbox']\n",
    "                    center_x = (bbox_coords['x1'] + bbox_coords['x2']) / 2\n",
    "                    center_y = (bbox_coords['y1'] + bbox_coords['y2']) / 2\n",
    "                    lat, lon = pixel_to_latlon(center_x, center_y, bounds, size)\n",
    "\n",
    "                    feature = {\n",
    "                        'type': 'Feature',\n",
    "                        'geometry': {'type': 'Point', 'coordinates': [lon, lat]},\n",
    "                        'properties': {\n",
    "                            'confidence': det['confidence'],\n",
    "                            'tile_id': result.get('image_id'),\n",
    "                            'model': 'yolo',\n",
    "                            'city': city_name\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    if not first:\n",
    "                        f.write(',\\n')\n",
    "                    f.write('    ' + json.dumps(feature))\n",
    "                    first = False\n",
    "\n",
    "        f.write('\\n  ]\\n}\\n')\n",
    "\n",
    "    logger.info(f\"{city_name} GeoJSON created: {yolo_path}\")\n",
    "    return yolo_path\n",
    "\n",
    "# ============================================================================\n",
    "# PART 11: RUN EVERYTHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING MULTI-CITY TREE DETECTION PIPELINE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Calculate and display tile counts for all cities\n",
    "print(\"PRE-PROCESSING ANALYSIS\")\n",
    "print(\"-\" * 70)\n",
    "total_estimated_tiles = 0\n",
    "for city_config in CITIES:\n",
    "    tiles_coords = list(mercantile.tiles(*city_config[\"bbox\"], zooms=ZOOM_LEVEL))\n",
    "    num_tiles = len(tiles_coords)\n",
    "    total_estimated_tiles += num_tiles\n",
    "    print(f\"  {city_config['name']:20s} : {num_tiles:6d} tiles\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  {'TOTAL':20s} : {total_estimated_tiles:6d} tiles\")\n",
    "print(f\"\\nEstimated processing time (at ~{DOWNLOAD_THREADS} tiles/sec): {total_estimated_tiles/DOWNLOAD_THREADS/60:.1f} minutes\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Load YOLO model ONCE at the beginning\n",
    "print(f\"Loading YOLO model from {YOLO_MODEL_PATH}...\")\n",
    "from ultralytics import YOLO\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "yolo_model.to(device)\n",
    "print(f\"YOLO model loaded successfully\\n\")\n",
    "\n",
    "# Initialize downloader with parallel threads\n",
    "downloader = TileDownloader(MAPTILER_API_KEY, num_threads=DOWNLOAD_THREADS)\n",
    "downloader.start()\n",
    "\n",
    "# Process each city\n",
    "all_cities_results = {}\n",
    "\n",
    "try:\n",
    "    for city_config in CITIES:\n",
    "        city_name = city_config[\"name\"]\n",
    "\n",
    "        # Run pipeline for this city\n",
    "        results, zoom = run_pipeline_parallel(\n",
    "            city_config=city_config,\n",
    "            yolo_model=yolo_model,\n",
    "            yolo_conf=YOLO_CONFIDENCE,\n",
    "            downloader=downloader,\n",
    "            device=device,\n",
    "            max_tiles=MAX_TILES,\n",
    "            zoom=ZOOM_LEVEL\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        all_cities_results[city_name] = {\n",
    "            \"results\": results,\n",
    "            \"zoom\": zoom,\n",
    "            \"output_folder\": os.path.join(OUTPUT_BASE_FOLDER, f\"{city_name}_zoom{zoom}\")\n",
    "        }\n",
    "\n",
    "        # Create GeoJSON for this city\n",
    "        if len(results) > 0:\n",
    "            output_folder = all_cities_results[city_name][\"output_folder\"]\n",
    "            geojson_path = create_geojson(results, output_folder, city_name)\n",
    "            all_cities_results[city_name][\"geojson\"] = geojson_path\n",
    "\n",
    "finally:\n",
    "    # Stop downloader threads\n",
    "    downloader.stop()\n",
    "\n",
    "# ============================================================================\n",
    "# PART 12: FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-CITY DETECTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_trees = 0\n",
    "total_tiles = 0\n",
    "total_failed = 0\n",
    "\n",
    "# Header for table\n",
    "print(f\"\\n{'CITY':<20} {'TILES':>8} {'FAILED':>8} {'TREES':>10} {'AVG TREES/TILE':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for city_name, city_data in all_cities_results.items():\n",
    "    results = city_data[\"results\"]\n",
    "    successful_results = [r for r in results if \"error\" not in r]\n",
    "    failed_results = len(results) - len(successful_results)\n",
    "    yolo_detections = sum(r.get(\"trees_detected\", 0) for r in successful_results)\n",
    "    avg_trees = yolo_detections / len(successful_results) if len(successful_results) > 0 else 0\n",
    "\n",
    "    total_trees += yolo_detections\n",
    "    total_tiles += len(successful_results)\n",
    "    total_failed += failed_results\n",
    "\n",
    "    print(f\"{city_name:<20} {len(successful_results):>8} {failed_results:>8} {yolo_detections:>10} {avg_trees:>15.2f}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'TOTAL':<20} {total_tiles:>8} {total_failed:>8} {total_trees:>10} {total_trees/total_tiles if total_tiles > 0 else 0:>15.2f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nRESULTS LOCATION:\")\n",
    "print(f\"   Base folder: {OUTPUT_BASE_FOLDER}\")\n",
    "print(f\"\\nOUTPUT FILES PER CITY:\")\n",
    "print(f\"   - [city]_zoom{ZOOM_LEVEL}/\")\n",
    "print(f\"     ├── [city]_yolo_detections.geojson  (map visualization)\")\n",
    "print(f\"     ├── [city]_processing.log            (detailed logs)\")\n",
    "print(f\"     └── json/tile_*_results.json         (individual tile results)\")\n",
    "\n",
    "print(f\"\\nPROCESSING CONFIGURATION:\")\n",
    "print(f\"   Model: YOLO11\")\n",
    "print(f\"   Confidence: {YOLO_CONFIDENCE}\")\n",
    "print(f\"   Zoom level: {ZOOM_LEVEL}\")\n",
    "print(f\"   Download threads: {DOWNLOAD_THREADS}\")\n",
    "print(f\"   Inference batch size: {INFERENCE_BATCH_SIZE}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "print(f\"\\nAll results saved to Google Drive!\")\n",
    "print(f\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
